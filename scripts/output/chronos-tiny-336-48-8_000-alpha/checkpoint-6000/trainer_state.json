{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.75,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00625,
      "grad_norm": 0.09599218517541885,
      "learning_rate": 0.00099375,
      "loss": 8.2534,
      "step": 50
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.2016817182302475,
      "learning_rate": 0.0009875,
      "loss": 7.9633,
      "step": 100
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.2907882630825043,
      "learning_rate": 0.00098125,
      "loss": 7.3718,
      "step": 150
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.31618112325668335,
      "learning_rate": 0.000975,
      "loss": 6.5707,
      "step": 200
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.25588083267211914,
      "learning_rate": 0.00096875,
      "loss": 5.8254,
      "step": 250
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.1770234853029251,
      "learning_rate": 0.0009625,
      "loss": 5.3516,
      "step": 300
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.1264151632785797,
      "learning_rate": 0.0009562500000000001,
      "loss": 5.0773,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.139504075050354,
      "learning_rate": 0.00095,
      "loss": 4.9338,
      "step": 400
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.11218240857124329,
      "learning_rate": 0.00094375,
      "loss": 4.8138,
      "step": 450
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.1946210116147995,
      "learning_rate": 0.0009375,
      "loss": 4.6842,
      "step": 500
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.13227041065692902,
      "learning_rate": 0.00093125,
      "loss": 4.5596,
      "step": 550
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.14373864233493805,
      "learning_rate": 0.000925,
      "loss": 4.3587,
      "step": 600
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.17127613723278046,
      "learning_rate": 0.00091875,
      "loss": 4.1664,
      "step": 650
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.18807174265384674,
      "learning_rate": 0.0009125,
      "loss": 3.9638,
      "step": 700
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.2272617369890213,
      "learning_rate": 0.00090625,
      "loss": 3.7573,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.27554404735565186,
      "learning_rate": 0.0009000000000000001,
      "loss": 3.5765,
      "step": 800
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.33136656880378723,
      "learning_rate": 0.00089375,
      "loss": 3.3527,
      "step": 850
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.21222379803657532,
      "learning_rate": 0.0008874999999999999,
      "loss": 3.1704,
      "step": 900
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.27104806900024414,
      "learning_rate": 0.00088125,
      "loss": 3.0084,
      "step": 950
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.306488960981369,
      "learning_rate": 0.000875,
      "loss": 2.825,
      "step": 1000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.31889814138412476,
      "learning_rate": 0.0008687500000000001,
      "loss": 2.6646,
      "step": 1050
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.33087843656539917,
      "learning_rate": 0.0008625000000000001,
      "loss": 2.5156,
      "step": 1100
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.36234039068222046,
      "learning_rate": 0.00085625,
      "loss": 2.3657,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39582496881484985,
      "learning_rate": 0.00085,
      "loss": 2.2162,
      "step": 1200
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.4480721950531006,
      "learning_rate": 0.00084375,
      "loss": 2.1243,
      "step": 1250
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.444683700799942,
      "learning_rate": 0.0008375,
      "loss": 1.9639,
      "step": 1300
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.4392201900482178,
      "learning_rate": 0.0008312500000000001,
      "loss": 1.8762,
      "step": 1350
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.40018177032470703,
      "learning_rate": 0.000825,
      "loss": 1.7716,
      "step": 1400
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.4393869936466217,
      "learning_rate": 0.00081875,
      "loss": 1.6457,
      "step": 1450
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.4581194519996643,
      "learning_rate": 0.0008125000000000001,
      "loss": 1.5668,
      "step": 1500
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.4058140516281128,
      "learning_rate": 0.00080625,
      "loss": 1.4842,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.483428418636322,
      "learning_rate": 0.0008,
      "loss": 1.4221,
      "step": 1600
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.4618244767189026,
      "learning_rate": 0.00079375,
      "loss": 1.3437,
      "step": 1650
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.46982088685035706,
      "learning_rate": 0.0007875,
      "loss": 1.2897,
      "step": 1700
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.4863327145576477,
      "learning_rate": 0.00078125,
      "loss": 1.2048,
      "step": 1750
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.4327215552330017,
      "learning_rate": 0.0007750000000000001,
      "loss": 1.1525,
      "step": 1800
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.43763095140457153,
      "learning_rate": 0.00076875,
      "loss": 1.1,
      "step": 1850
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.4670902192592621,
      "learning_rate": 0.0007624999999999999,
      "loss": 1.0343,
      "step": 1900
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.4677627980709076,
      "learning_rate": 0.00075625,
      "loss": 0.9844,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5218617916107178,
      "learning_rate": 0.00075,
      "loss": 0.9728,
      "step": 2000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 0.4728618562221527,
      "learning_rate": 0.00074375,
      "loss": 0.9389,
      "step": 2050
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.5470054149627686,
      "learning_rate": 0.0007375000000000001,
      "loss": 0.8838,
      "step": 2100
    },
    {
      "epoch": 0.26875,
      "grad_norm": 0.4243176281452179,
      "learning_rate": 0.00073125,
      "loss": 0.8635,
      "step": 2150
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.4983800947666168,
      "learning_rate": 0.000725,
      "loss": 0.8381,
      "step": 2200
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.5332600474357605,
      "learning_rate": 0.00071875,
      "loss": 0.8023,
      "step": 2250
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.5224674940109253,
      "learning_rate": 0.0007125,
      "loss": 0.7769,
      "step": 2300
    },
    {
      "epoch": 0.29375,
      "grad_norm": 0.4533703327178955,
      "learning_rate": 0.0007062500000000001,
      "loss": 0.7563,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5139030814170837,
      "learning_rate": 0.0007,
      "loss": 0.7321,
      "step": 2400
    },
    {
      "epoch": 0.30625,
      "grad_norm": 0.5188442468643188,
      "learning_rate": 0.00069375,
      "loss": 0.7136,
      "step": 2450
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.4954397678375244,
      "learning_rate": 0.0006875,
      "loss": 0.6927,
      "step": 2500
    },
    {
      "epoch": 0.31875,
      "grad_norm": 0.4713590443134308,
      "learning_rate": 0.00068125,
      "loss": 0.675,
      "step": 2550
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.4925381541252136,
      "learning_rate": 0.000675,
      "loss": 0.6638,
      "step": 2600
    },
    {
      "epoch": 0.33125,
      "grad_norm": 0.5115794539451599,
      "learning_rate": 0.00066875,
      "loss": 0.6501,
      "step": 2650
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.5040227770805359,
      "learning_rate": 0.0006625,
      "loss": 0.6524,
      "step": 2700
    },
    {
      "epoch": 0.34375,
      "grad_norm": 0.40075016021728516,
      "learning_rate": 0.00065625,
      "loss": 0.6114,
      "step": 2750
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4715745151042938,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.5996,
      "step": 2800
    },
    {
      "epoch": 0.35625,
      "grad_norm": 0.546543538570404,
      "learning_rate": 0.00064375,
      "loss": 0.5963,
      "step": 2850
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.5216814875602722,
      "learning_rate": 0.0006374999999999999,
      "loss": 0.5794,
      "step": 2900
    },
    {
      "epoch": 0.36875,
      "grad_norm": 0.4839549958705902,
      "learning_rate": 0.00063125,
      "loss": 0.5783,
      "step": 2950
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.4818575382232666,
      "learning_rate": 0.000625,
      "loss": 0.5658,
      "step": 3000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 0.4748634696006775,
      "learning_rate": 0.00061875,
      "loss": 0.5445,
      "step": 3050
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.45028895139694214,
      "learning_rate": 0.0006125000000000001,
      "loss": 0.5388,
      "step": 3100
    },
    {
      "epoch": 0.39375,
      "grad_norm": 0.4212864339351654,
      "learning_rate": 0.00060625,
      "loss": 0.5305,
      "step": 3150
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.48015478253364563,
      "learning_rate": 0.0006,
      "loss": 0.5205,
      "step": 3200
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.5114849805831909,
      "learning_rate": 0.00059375,
      "loss": 0.5166,
      "step": 3250
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.3941650688648224,
      "learning_rate": 0.0005875,
      "loss": 0.508,
      "step": 3300
    },
    {
      "epoch": 0.41875,
      "grad_norm": 0.5147479176521301,
      "learning_rate": 0.0005812500000000001,
      "loss": 0.5091,
      "step": 3350
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.48032259941101074,
      "learning_rate": 0.000575,
      "loss": 0.4934,
      "step": 3400
    },
    {
      "epoch": 0.43125,
      "grad_norm": 0.5508254766464233,
      "learning_rate": 0.00056875,
      "loss": 0.4875,
      "step": 3450
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.47924304008483887,
      "learning_rate": 0.0005625000000000001,
      "loss": 0.4734,
      "step": 3500
    },
    {
      "epoch": 0.44375,
      "grad_norm": 0.47096797823905945,
      "learning_rate": 0.00055625,
      "loss": 0.4925,
      "step": 3550
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4015507996082306,
      "learning_rate": 0.00055,
      "loss": 0.4795,
      "step": 3600
    },
    {
      "epoch": 0.45625,
      "grad_norm": 0.48435908555984497,
      "learning_rate": 0.00054375,
      "loss": 0.4706,
      "step": 3650
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.5635468363761902,
      "learning_rate": 0.0005375,
      "loss": 0.469,
      "step": 3700
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.4240591526031494,
      "learning_rate": 0.00053125,
      "loss": 0.4588,
      "step": 3750
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.471486896276474,
      "learning_rate": 0.0005250000000000001,
      "loss": 0.4501,
      "step": 3800
    },
    {
      "epoch": 0.48125,
      "grad_norm": 0.5072925686836243,
      "learning_rate": 0.00051875,
      "loss": 0.4557,
      "step": 3850
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.4846518635749817,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.4488,
      "step": 3900
    },
    {
      "epoch": 0.49375,
      "grad_norm": 0.4031444787979126,
      "learning_rate": 0.00050625,
      "loss": 0.4417,
      "step": 3950
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.44835591316223145,
      "learning_rate": 0.0005,
      "loss": 0.4331,
      "step": 4000
    },
    {
      "epoch": 0.50625,
      "grad_norm": 0.5373079180717468,
      "learning_rate": 0.00049375,
      "loss": 0.4258,
      "step": 4050
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.42789721488952637,
      "learning_rate": 0.0004875,
      "loss": 0.4246,
      "step": 4100
    },
    {
      "epoch": 0.51875,
      "grad_norm": 0.458732008934021,
      "learning_rate": 0.00048125,
      "loss": 0.4208,
      "step": 4150
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.506213903427124,
      "learning_rate": 0.000475,
      "loss": 0.4134,
      "step": 4200
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.4343845844268799,
      "learning_rate": 0.00046875,
      "loss": 0.4194,
      "step": 4250
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.46829545497894287,
      "learning_rate": 0.0004625,
      "loss": 0.4059,
      "step": 4300
    },
    {
      "epoch": 0.54375,
      "grad_norm": 0.4375130236148834,
      "learning_rate": 0.00045625,
      "loss": 0.4114,
      "step": 4350
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4565381705760956,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.3934,
      "step": 4400
    },
    {
      "epoch": 0.55625,
      "grad_norm": 0.4590267837047577,
      "learning_rate": 0.00044374999999999997,
      "loss": 0.3917,
      "step": 4450
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.4331663250923157,
      "learning_rate": 0.0004375,
      "loss": 0.3892,
      "step": 4500
    },
    {
      "epoch": 0.56875,
      "grad_norm": 0.45390260219573975,
      "learning_rate": 0.00043125000000000005,
      "loss": 0.3961,
      "step": 4550
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.4355538785457611,
      "learning_rate": 0.000425,
      "loss": 0.4039,
      "step": 4600
    },
    {
      "epoch": 0.58125,
      "grad_norm": 0.48167937994003296,
      "learning_rate": 0.00041875,
      "loss": 0.3973,
      "step": 4650
    },
    {
      "epoch": 0.5875,
      "grad_norm": 0.4496619403362274,
      "learning_rate": 0.0004125,
      "loss": 0.3771,
      "step": 4700
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.4740627706050873,
      "learning_rate": 0.00040625000000000004,
      "loss": 0.3692,
      "step": 4750
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.43896356225013733,
      "learning_rate": 0.0004,
      "loss": 0.3826,
      "step": 4800
    },
    {
      "epoch": 0.60625,
      "grad_norm": 0.4179669916629791,
      "learning_rate": 0.00039375,
      "loss": 0.376,
      "step": 4850
    },
    {
      "epoch": 0.6125,
      "grad_norm": 0.3992711901664734,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.373,
      "step": 4900
    },
    {
      "epoch": 0.61875,
      "grad_norm": 0.5136942267417908,
      "learning_rate": 0.00038124999999999997,
      "loss": 0.3661,
      "step": 4950
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.4091406464576721,
      "learning_rate": 0.000375,
      "loss": 0.3704,
      "step": 5000
    },
    {
      "epoch": 0.63125,
      "grad_norm": 0.5371158719062805,
      "learning_rate": 0.00036875000000000005,
      "loss": 0.3741,
      "step": 5050
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.4309271574020386,
      "learning_rate": 0.0003625,
      "loss": 0.3627,
      "step": 5100
    },
    {
      "epoch": 0.64375,
      "grad_norm": 0.47524115443229675,
      "learning_rate": 0.00035625,
      "loss": 0.3651,
      "step": 5150
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.471285879611969,
      "learning_rate": 0.00035,
      "loss": 0.3606,
      "step": 5200
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.41712480783462524,
      "learning_rate": 0.00034375,
      "loss": 0.3533,
      "step": 5250
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.5149484872817993,
      "learning_rate": 0.0003375,
      "loss": 0.3565,
      "step": 5300
    },
    {
      "epoch": 0.66875,
      "grad_norm": 0.4436168074607849,
      "learning_rate": 0.00033125,
      "loss": 0.3536,
      "step": 5350
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.3735876679420471,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.3569,
      "step": 5400
    },
    {
      "epoch": 0.68125,
      "grad_norm": 0.3855494558811188,
      "learning_rate": 0.00031874999999999997,
      "loss": 0.3492,
      "step": 5450
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.4542533755302429,
      "learning_rate": 0.0003125,
      "loss": 0.343,
      "step": 5500
    },
    {
      "epoch": 0.69375,
      "grad_norm": 0.3963911533355713,
      "learning_rate": 0.00030625000000000004,
      "loss": 0.3454,
      "step": 5550
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4460110366344452,
      "learning_rate": 0.0003,
      "loss": 0.3361,
      "step": 5600
    },
    {
      "epoch": 0.70625,
      "grad_norm": 0.39286330342292786,
      "learning_rate": 0.00029375,
      "loss": 0.3432,
      "step": 5650
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.4411306381225586,
      "learning_rate": 0.0002875,
      "loss": 0.3368,
      "step": 5700
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.46366801857948303,
      "learning_rate": 0.00028125000000000003,
      "loss": 0.3346,
      "step": 5750
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.3685435950756073,
      "learning_rate": 0.000275,
      "loss": 0.3284,
      "step": 5800
    },
    {
      "epoch": 0.73125,
      "grad_norm": 0.48025164008140564,
      "learning_rate": 0.00026875,
      "loss": 0.3334,
      "step": 5850
    },
    {
      "epoch": 0.7375,
      "grad_norm": 0.3881779611110687,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.3299,
      "step": 5900
    },
    {
      "epoch": 0.74375,
      "grad_norm": 0.5003681182861328,
      "learning_rate": 0.00025624999999999997,
      "loss": 0.3361,
      "step": 5950
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.41555163264274597,
      "learning_rate": 0.00025,
      "loss": 0.3235,
      "step": 6000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2851763060736000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
