{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00625,
      "grad_norm": 0.09266215562820435,
      "learning_rate": 0.00099375,
      "loss": 8.2563,
      "step": 50
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.2014138400554657,
      "learning_rate": 0.0009875,
      "loss": 7.9584,
      "step": 100
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.29581573605537415,
      "learning_rate": 0.00098125,
      "loss": 7.3603,
      "step": 150
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.3109932243824005,
      "learning_rate": 0.000975,
      "loss": 6.564,
      "step": 200
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.23517319560050964,
      "learning_rate": 0.00096875,
      "loss": 5.8346,
      "step": 250
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.15853969752788544,
      "learning_rate": 0.0009625,
      "loss": 5.3987,
      "step": 300
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.1467609405517578,
      "learning_rate": 0.0009562500000000001,
      "loss": 5.1993,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.07835017144680023,
      "learning_rate": 0.00095,
      "loss": 5.1098,
      "step": 400
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.07526788115501404,
      "learning_rate": 0.00094375,
      "loss": 5.0399,
      "step": 450
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.07025665044784546,
      "learning_rate": 0.0009375,
      "loss": 4.9993,
      "step": 500
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.08182492107152939,
      "learning_rate": 0.00093125,
      "loss": 4.9258,
      "step": 550
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.11438523232936859,
      "learning_rate": 0.000925,
      "loss": 4.8437,
      "step": 600
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.10080917179584503,
      "learning_rate": 0.00091875,
      "loss": 4.742,
      "step": 650
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.11214131116867065,
      "learning_rate": 0.0009125,
      "loss": 4.6289,
      "step": 700
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.16700947284698486,
      "learning_rate": 0.00090625,
      "loss": 4.4994,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1823149472475052,
      "learning_rate": 0.0009000000000000001,
      "loss": 4.3543,
      "step": 800
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.276734322309494,
      "learning_rate": 0.00089375,
      "loss": 4.1955,
      "step": 850
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.2573646903038025,
      "learning_rate": 0.0008874999999999999,
      "loss": 4.0265,
      "step": 900
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.2644428312778473,
      "learning_rate": 0.00088125,
      "loss": 3.8636,
      "step": 950
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.28038540482521057,
      "learning_rate": 0.000875,
      "loss": 3.6874,
      "step": 1000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.3641144037246704,
      "learning_rate": 0.0008687500000000001,
      "loss": 3.51,
      "step": 1050
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.3245958089828491,
      "learning_rate": 0.0008625000000000001,
      "loss": 3.321,
      "step": 1100
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.4304158389568329,
      "learning_rate": 0.00085625,
      "loss": 3.146,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4222780466079712,
      "learning_rate": 0.00085,
      "loss": 2.9626,
      "step": 1200
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.4637942910194397,
      "learning_rate": 0.00084375,
      "loss": 2.7718,
      "step": 1250
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.4194587469100952,
      "learning_rate": 0.0008375,
      "loss": 2.5852,
      "step": 1300
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.4228289723396301,
      "learning_rate": 0.0008312500000000001,
      "loss": 2.4254,
      "step": 1350
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.5203415155410767,
      "learning_rate": 0.000825,
      "loss": 2.2558,
      "step": 1400
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.513689398765564,
      "learning_rate": 0.00081875,
      "loss": 2.0906,
      "step": 1450
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.48652908205986023,
      "learning_rate": 0.0008125000000000001,
      "loss": 1.9512,
      "step": 1500
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.4514564275741577,
      "learning_rate": 0.00080625,
      "loss": 1.8282,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5045268535614014,
      "learning_rate": 0.0008,
      "loss": 1.7245,
      "step": 1600
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.424803763628006,
      "learning_rate": 0.00079375,
      "loss": 1.5969,
      "step": 1650
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.6004962921142578,
      "learning_rate": 0.0007875,
      "loss": 1.5383,
      "step": 1700
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5223739743232727,
      "learning_rate": 0.00078125,
      "loss": 1.4378,
      "step": 1750
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.5205168128013611,
      "learning_rate": 0.0007750000000000001,
      "loss": 1.3941,
      "step": 1800
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.45318594574928284,
      "learning_rate": 0.00076875,
      "loss": 1.3158,
      "step": 1850
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.42733538150787354,
      "learning_rate": 0.0007624999999999999,
      "loss": 1.2737,
      "step": 1900
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.42159679532051086,
      "learning_rate": 0.00075625,
      "loss": 1.2082,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.458441823720932,
      "learning_rate": 0.00075,
      "loss": 1.1711,
      "step": 2000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 0.4171815812587738,
      "learning_rate": 0.00074375,
      "loss": 1.1229,
      "step": 2050
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.5856695175170898,
      "learning_rate": 0.0007375000000000001,
      "loss": 1.0872,
      "step": 2100
    },
    {
      "epoch": 0.26875,
      "grad_norm": 0.44208210706710815,
      "learning_rate": 0.00073125,
      "loss": 1.0487,
      "step": 2150
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.44768089056015015,
      "learning_rate": 0.000725,
      "loss": 1.016,
      "step": 2200
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.5629771947860718,
      "learning_rate": 0.00071875,
      "loss": 0.9847,
      "step": 2250
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.526421844959259,
      "learning_rate": 0.0007125,
      "loss": 0.9593,
      "step": 2300
    },
    {
      "epoch": 0.29375,
      "grad_norm": 0.49641942977905273,
      "learning_rate": 0.0007062500000000001,
      "loss": 0.9288,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.45160195231437683,
      "learning_rate": 0.0007,
      "loss": 0.9001,
      "step": 2400
    },
    {
      "epoch": 0.30625,
      "grad_norm": 0.4642001688480377,
      "learning_rate": 0.00069375,
      "loss": 0.8945,
      "step": 2450
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.43231162428855896,
      "learning_rate": 0.0006875,
      "loss": 0.8659,
      "step": 2500
    },
    {
      "epoch": 0.31875,
      "grad_norm": 0.4811435341835022,
      "learning_rate": 0.00068125,
      "loss": 0.8424,
      "step": 2550
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.5004189014434814,
      "learning_rate": 0.000675,
      "loss": 0.8277,
      "step": 2600
    },
    {
      "epoch": 0.33125,
      "grad_norm": 0.4896371066570282,
      "learning_rate": 0.00066875,
      "loss": 0.8085,
      "step": 2650
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.4578609764575958,
      "learning_rate": 0.0006625,
      "loss": 0.7849,
      "step": 2700
    },
    {
      "epoch": 0.34375,
      "grad_norm": 0.4221917688846588,
      "learning_rate": 0.00065625,
      "loss": 0.7614,
      "step": 2750
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5420978665351868,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.7521,
      "step": 2800
    },
    {
      "epoch": 0.35625,
      "grad_norm": 0.49207526445388794,
      "learning_rate": 0.00064375,
      "loss": 0.722,
      "step": 2850
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.42947179079055786,
      "learning_rate": 0.0006374999999999999,
      "loss": 0.704,
      "step": 2900
    },
    {
      "epoch": 0.36875,
      "grad_norm": 0.4506109952926636,
      "learning_rate": 0.00063125,
      "loss": 0.6963,
      "step": 2950
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.45438259840011597,
      "learning_rate": 0.000625,
      "loss": 0.6837,
      "step": 3000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 0.43589726090431213,
      "learning_rate": 0.00061875,
      "loss": 0.6769,
      "step": 3050
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.4416930377483368,
      "learning_rate": 0.0006125000000000001,
      "loss": 0.6503,
      "step": 3100
    },
    {
      "epoch": 0.39375,
      "grad_norm": 0.43455827236175537,
      "learning_rate": 0.00060625,
      "loss": 0.6465,
      "step": 3150
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4983147978782654,
      "learning_rate": 0.0006,
      "loss": 0.6287,
      "step": 3200
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.5128852128982544,
      "learning_rate": 0.00059375,
      "loss": 0.634,
      "step": 3250
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.43828070163726807,
      "learning_rate": 0.0005875,
      "loss": 0.6186,
      "step": 3300
    },
    {
      "epoch": 0.41875,
      "grad_norm": 0.5450947880744934,
      "learning_rate": 0.0005812500000000001,
      "loss": 0.628,
      "step": 3350
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.3683299422264099,
      "learning_rate": 0.000575,
      "loss": 0.6066,
      "step": 3400
    },
    {
      "epoch": 0.43125,
      "grad_norm": 0.4364549517631531,
      "learning_rate": 0.00056875,
      "loss": 0.5914,
      "step": 3450
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.4552922248840332,
      "learning_rate": 0.0005625000000000001,
      "loss": 0.5901,
      "step": 3500
    },
    {
      "epoch": 0.44375,
      "grad_norm": 0.46128103137016296,
      "learning_rate": 0.00055625,
      "loss": 0.5812,
      "step": 3550
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4764719605445862,
      "learning_rate": 0.00055,
      "loss": 0.5755,
      "step": 3600
    },
    {
      "epoch": 0.45625,
      "grad_norm": 0.5028109550476074,
      "learning_rate": 0.00054375,
      "loss": 0.5725,
      "step": 3650
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.45613500475883484,
      "learning_rate": 0.0005375,
      "loss": 0.551,
      "step": 3700
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.5288267135620117,
      "learning_rate": 0.00053125,
      "loss": 0.5487,
      "step": 3750
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.4203225076198578,
      "learning_rate": 0.0005250000000000001,
      "loss": 0.5401,
      "step": 3800
    },
    {
      "epoch": 0.48125,
      "grad_norm": 0.5093460083007812,
      "learning_rate": 0.00051875,
      "loss": 0.5414,
      "step": 3850
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.447041392326355,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.5349,
      "step": 3900
    },
    {
      "epoch": 0.49375,
      "grad_norm": 0.4288078248500824,
      "learning_rate": 0.00050625,
      "loss": 0.523,
      "step": 3950
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.40479692816734314,
      "learning_rate": 0.0005,
      "loss": 0.5222,
      "step": 4000
    },
    {
      "epoch": 0.50625,
      "grad_norm": 0.44290366768836975,
      "learning_rate": 0.00049375,
      "loss": 0.5084,
      "step": 4050
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.42069223523139954,
      "learning_rate": 0.0004875,
      "loss": 0.503,
      "step": 4100
    },
    {
      "epoch": 0.51875,
      "grad_norm": 0.49223893880844116,
      "learning_rate": 0.00048125,
      "loss": 0.508,
      "step": 4150
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.4454716742038727,
      "learning_rate": 0.000475,
      "loss": 0.4963,
      "step": 4200
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.47917500138282776,
      "learning_rate": 0.00046875,
      "loss": 0.494,
      "step": 4250
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.44867879152297974,
      "learning_rate": 0.0004625,
      "loss": 0.4894,
      "step": 4300
    },
    {
      "epoch": 0.54375,
      "grad_norm": 0.4213130474090576,
      "learning_rate": 0.00045625,
      "loss": 0.4874,
      "step": 4350
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.40542125701904297,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4729,
      "step": 4400
    },
    {
      "epoch": 0.55625,
      "grad_norm": 0.4231424033641815,
      "learning_rate": 0.00044374999999999997,
      "loss": 0.4758,
      "step": 4450
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.46233123540878296,
      "learning_rate": 0.0004375,
      "loss": 0.47,
      "step": 4500
    },
    {
      "epoch": 0.56875,
      "grad_norm": 0.4753783941268921,
      "learning_rate": 0.00043125000000000005,
      "loss": 0.4612,
      "step": 4550
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.4293246269226074,
      "learning_rate": 0.000425,
      "loss": 0.4805,
      "step": 4600
    },
    {
      "epoch": 0.58125,
      "grad_norm": 0.4910587966442108,
      "learning_rate": 0.00041875,
      "loss": 0.4717,
      "step": 4650
    },
    {
      "epoch": 0.5875,
      "grad_norm": 0.4147769808769226,
      "learning_rate": 0.0004125,
      "loss": 0.4524,
      "step": 4700
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.41815099120140076,
      "learning_rate": 0.00040625000000000004,
      "loss": 0.4478,
      "step": 4750
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48531538248062134,
      "learning_rate": 0.0004,
      "loss": 0.4531,
      "step": 4800
    },
    {
      "epoch": 0.60625,
      "grad_norm": 0.4411671757698059,
      "learning_rate": 0.00039375,
      "loss": 0.4493,
      "step": 4850
    },
    {
      "epoch": 0.6125,
      "grad_norm": 0.4414498209953308,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4401,
      "step": 4900
    },
    {
      "epoch": 0.61875,
      "grad_norm": 0.4157997965812683,
      "learning_rate": 0.00038124999999999997,
      "loss": 0.4436,
      "step": 4950
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.49458351731300354,
      "learning_rate": 0.000375,
      "loss": 0.4417,
      "step": 5000
    },
    {
      "epoch": 0.63125,
      "grad_norm": 0.5104137063026428,
      "learning_rate": 0.00036875000000000005,
      "loss": 0.4504,
      "step": 5050
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.3764137029647827,
      "learning_rate": 0.0003625,
      "loss": 0.4347,
      "step": 5100
    },
    {
      "epoch": 0.64375,
      "grad_norm": 0.48627153038978577,
      "learning_rate": 0.00035625,
      "loss": 0.4317,
      "step": 5150
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4770093560218811,
      "learning_rate": 0.00035,
      "loss": 0.4241,
      "step": 5200
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.43363258242607117,
      "learning_rate": 0.00034375,
      "loss": 0.4148,
      "step": 5250
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.4211578071117401,
      "learning_rate": 0.0003375,
      "loss": 0.4231,
      "step": 5300
    },
    {
      "epoch": 0.66875,
      "grad_norm": 0.40471431612968445,
      "learning_rate": 0.00033125,
      "loss": 0.4107,
      "step": 5350
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.3773914575576782,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4186,
      "step": 5400
    },
    {
      "epoch": 0.68125,
      "grad_norm": 0.4191606342792511,
      "learning_rate": 0.00031874999999999997,
      "loss": 0.4129,
      "step": 5450
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.5380475521087646,
      "learning_rate": 0.0003125,
      "loss": 0.4087,
      "step": 5500
    },
    {
      "epoch": 0.69375,
      "grad_norm": 0.4405691921710968,
      "learning_rate": 0.00030625000000000004,
      "loss": 0.4128,
      "step": 5550
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.42695435881614685,
      "learning_rate": 0.0003,
      "loss": 0.4015,
      "step": 5600
    },
    {
      "epoch": 0.70625,
      "grad_norm": 0.4654732644557953,
      "learning_rate": 0.00029375,
      "loss": 0.3991,
      "step": 5650
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.44689974188804626,
      "learning_rate": 0.0002875,
      "loss": 0.4124,
      "step": 5700
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.4349694550037384,
      "learning_rate": 0.00028125000000000003,
      "loss": 0.4089,
      "step": 5750
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.45331764221191406,
      "learning_rate": 0.000275,
      "loss": 0.397,
      "step": 5800
    },
    {
      "epoch": 0.73125,
      "grad_norm": 0.49022653698921204,
      "learning_rate": 0.00026875,
      "loss": 0.4034,
      "step": 5850
    },
    {
      "epoch": 0.7375,
      "grad_norm": 0.43151023983955383,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.3967,
      "step": 5900
    },
    {
      "epoch": 0.74375,
      "grad_norm": 0.4365711510181427,
      "learning_rate": 0.00025624999999999997,
      "loss": 0.3927,
      "step": 5950
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3855059742927551,
      "learning_rate": 0.00025,
      "loss": 0.3806,
      "step": 6000
    },
    {
      "epoch": 0.75625,
      "grad_norm": 0.4151966869831085,
      "learning_rate": 0.00024375,
      "loss": 0.3807,
      "step": 6050
    },
    {
      "epoch": 0.7625,
      "grad_norm": 0.41311752796173096,
      "learning_rate": 0.0002375,
      "loss": 0.3899,
      "step": 6100
    },
    {
      "epoch": 0.76875,
      "grad_norm": 0.4030155837535858,
      "learning_rate": 0.00023125,
      "loss": 0.3912,
      "step": 6150
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.3831643760204315,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.3734,
      "step": 6200
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.3915643095970154,
      "learning_rate": 0.00021875,
      "loss": 0.3827,
      "step": 6250
    },
    {
      "epoch": 0.7875,
      "grad_norm": 0.4673191010951996,
      "learning_rate": 0.0002125,
      "loss": 0.3772,
      "step": 6300
    },
    {
      "epoch": 0.79375,
      "grad_norm": 0.4091850817203522,
      "learning_rate": 0.00020625,
      "loss": 0.3724,
      "step": 6350
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4461764693260193,
      "learning_rate": 0.0002,
      "loss": 0.3742,
      "step": 6400
    },
    {
      "epoch": 0.80625,
      "grad_norm": 0.43480193614959717,
      "learning_rate": 0.00019375000000000002,
      "loss": 0.3722,
      "step": 6450
    },
    {
      "epoch": 0.8125,
      "grad_norm": 0.4600208103656769,
      "learning_rate": 0.0001875,
      "loss": 0.3772,
      "step": 6500
    },
    {
      "epoch": 0.81875,
      "grad_norm": 0.39710667729377747,
      "learning_rate": 0.00018125,
      "loss": 0.3698,
      "step": 6550
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.3679569959640503,
      "learning_rate": 0.000175,
      "loss": 0.3715,
      "step": 6600
    },
    {
      "epoch": 0.83125,
      "grad_norm": 0.4620541036128998,
      "learning_rate": 0.00016875,
      "loss": 0.3663,
      "step": 6650
    },
    {
      "epoch": 0.8375,
      "grad_norm": 0.532548725605011,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.3671,
      "step": 6700
    },
    {
      "epoch": 0.84375,
      "grad_norm": 0.4071497917175293,
      "learning_rate": 0.00015625,
      "loss": 0.3704,
      "step": 6750
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.40703678131103516,
      "learning_rate": 0.00015,
      "loss": 0.3589,
      "step": 6800
    },
    {
      "epoch": 0.85625,
      "grad_norm": 0.4268624186515808,
      "learning_rate": 0.00014375,
      "loss": 0.3705,
      "step": 6850
    },
    {
      "epoch": 0.8625,
      "grad_norm": 0.4071905314922333,
      "learning_rate": 0.0001375,
      "loss": 0.3641,
      "step": 6900
    },
    {
      "epoch": 0.86875,
      "grad_norm": 0.4498610496520996,
      "learning_rate": 0.00013125000000000002,
      "loss": 0.362,
      "step": 6950
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.3676159679889679,
      "learning_rate": 0.000125,
      "loss": 0.353,
      "step": 7000
    },
    {
      "epoch": 0.88125,
      "grad_norm": 0.38222619891166687,
      "learning_rate": 0.00011875,
      "loss": 0.3615,
      "step": 7050
    },
    {
      "epoch": 0.8875,
      "grad_norm": 0.3793940544128418,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.3494,
      "step": 7100
    },
    {
      "epoch": 0.89375,
      "grad_norm": 0.4021280109882355,
      "learning_rate": 0.00010625,
      "loss": 0.3597,
      "step": 7150
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3944079875946045,
      "learning_rate": 0.0001,
      "loss": 0.3493,
      "step": 7200
    },
    {
      "epoch": 0.90625,
      "grad_norm": 0.44789591431617737,
      "learning_rate": 9.375e-05,
      "loss": 0.3504,
      "step": 7250
    },
    {
      "epoch": 0.9125,
      "grad_norm": 0.4057807922363281,
      "learning_rate": 8.75e-05,
      "loss": 0.3558,
      "step": 7300
    },
    {
      "epoch": 0.91875,
      "grad_norm": 0.43594881892204285,
      "learning_rate": 8.125000000000001e-05,
      "loss": 0.3455,
      "step": 7350
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.42066866159439087,
      "learning_rate": 7.5e-05,
      "loss": 0.3508,
      "step": 7400
    },
    {
      "epoch": 0.93125,
      "grad_norm": 0.40435436367988586,
      "learning_rate": 6.875e-05,
      "loss": 0.3423,
      "step": 7450
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.3540579676628113,
      "learning_rate": 6.25e-05,
      "loss": 0.3464,
      "step": 7500
    },
    {
      "epoch": 0.94375,
      "grad_norm": 0.39742788672447205,
      "learning_rate": 5.6250000000000005e-05,
      "loss": 0.3539,
      "step": 7550
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4586065411567688,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 7600
    },
    {
      "epoch": 0.95625,
      "grad_norm": 0.4659780263900757,
      "learning_rate": 4.375e-05,
      "loss": 0.3589,
      "step": 7650
    },
    {
      "epoch": 0.9625,
      "grad_norm": 0.3827533721923828,
      "learning_rate": 3.75e-05,
      "loss": 0.3475,
      "step": 7700
    },
    {
      "epoch": 0.96875,
      "grad_norm": 0.4512232840061188,
      "learning_rate": 3.125e-05,
      "loss": 0.3512,
      "step": 7750
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.34249061346054077,
      "learning_rate": 2.5e-05,
      "loss": 0.3582,
      "step": 7800
    },
    {
      "epoch": 0.98125,
      "grad_norm": 0.4293670356273651,
      "learning_rate": 1.875e-05,
      "loss": 0.3507,
      "step": 7850
    },
    {
      "epoch": 0.9875,
      "grad_norm": 0.4167564809322357,
      "learning_rate": 1.25e-05,
      "loss": 0.3398,
      "step": 7900
    },
    {
      "epoch": 0.99375,
      "grad_norm": 0.4393934905529022,
      "learning_rate": 6.25e-06,
      "loss": 0.3499,
      "step": 7950
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4523181915283203,
      "learning_rate": 0.0,
      "loss": 0.354,
      "step": 8000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3802350747648000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
