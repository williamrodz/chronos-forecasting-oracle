{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.25,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00625,
      "grad_norm": 0.09266215562820435,
      "learning_rate": 0.00099375,
      "loss": 8.2563,
      "step": 50
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.2014138400554657,
      "learning_rate": 0.0009875,
      "loss": 7.9584,
      "step": 100
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.29581573605537415,
      "learning_rate": 0.00098125,
      "loss": 7.3603,
      "step": 150
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.3109932243824005,
      "learning_rate": 0.000975,
      "loss": 6.564,
      "step": 200
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.23517319560050964,
      "learning_rate": 0.00096875,
      "loss": 5.8346,
      "step": 250
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.15853969752788544,
      "learning_rate": 0.0009625,
      "loss": 5.3987,
      "step": 300
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.1467609405517578,
      "learning_rate": 0.0009562500000000001,
      "loss": 5.1993,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.07835017144680023,
      "learning_rate": 0.00095,
      "loss": 5.1098,
      "step": 400
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.07526788115501404,
      "learning_rate": 0.00094375,
      "loss": 5.0399,
      "step": 450
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.07025665044784546,
      "learning_rate": 0.0009375,
      "loss": 4.9993,
      "step": 500
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.08182492107152939,
      "learning_rate": 0.00093125,
      "loss": 4.9258,
      "step": 550
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.11438523232936859,
      "learning_rate": 0.000925,
      "loss": 4.8437,
      "step": 600
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.10080917179584503,
      "learning_rate": 0.00091875,
      "loss": 4.742,
      "step": 650
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.11214131116867065,
      "learning_rate": 0.0009125,
      "loss": 4.6289,
      "step": 700
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.16700947284698486,
      "learning_rate": 0.00090625,
      "loss": 4.4994,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1823149472475052,
      "learning_rate": 0.0009000000000000001,
      "loss": 4.3543,
      "step": 800
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.276734322309494,
      "learning_rate": 0.00089375,
      "loss": 4.1955,
      "step": 850
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.2573646903038025,
      "learning_rate": 0.0008874999999999999,
      "loss": 4.0265,
      "step": 900
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.2644428312778473,
      "learning_rate": 0.00088125,
      "loss": 3.8636,
      "step": 950
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.28038540482521057,
      "learning_rate": 0.000875,
      "loss": 3.6874,
      "step": 1000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.3641144037246704,
      "learning_rate": 0.0008687500000000001,
      "loss": 3.51,
      "step": 1050
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.3245958089828491,
      "learning_rate": 0.0008625000000000001,
      "loss": 3.321,
      "step": 1100
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.4304158389568329,
      "learning_rate": 0.00085625,
      "loss": 3.146,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4222780466079712,
      "learning_rate": 0.00085,
      "loss": 2.9626,
      "step": 1200
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.4637942910194397,
      "learning_rate": 0.00084375,
      "loss": 2.7718,
      "step": 1250
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.4194587469100952,
      "learning_rate": 0.0008375,
      "loss": 2.5852,
      "step": 1300
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.4228289723396301,
      "learning_rate": 0.0008312500000000001,
      "loss": 2.4254,
      "step": 1350
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.5203415155410767,
      "learning_rate": 0.000825,
      "loss": 2.2558,
      "step": 1400
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.513689398765564,
      "learning_rate": 0.00081875,
      "loss": 2.0906,
      "step": 1450
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.48652908205986023,
      "learning_rate": 0.0008125000000000001,
      "loss": 1.9512,
      "step": 1500
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.4514564275741577,
      "learning_rate": 0.00080625,
      "loss": 1.8282,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5045268535614014,
      "learning_rate": 0.0008,
      "loss": 1.7245,
      "step": 1600
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.424803763628006,
      "learning_rate": 0.00079375,
      "loss": 1.5969,
      "step": 1650
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.6004962921142578,
      "learning_rate": 0.0007875,
      "loss": 1.5383,
      "step": 1700
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5223739743232727,
      "learning_rate": 0.00078125,
      "loss": 1.4378,
      "step": 1750
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.5205168128013611,
      "learning_rate": 0.0007750000000000001,
      "loss": 1.3941,
      "step": 1800
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.45318594574928284,
      "learning_rate": 0.00076875,
      "loss": 1.3158,
      "step": 1850
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.42733538150787354,
      "learning_rate": 0.0007624999999999999,
      "loss": 1.2737,
      "step": 1900
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.42159679532051086,
      "learning_rate": 0.00075625,
      "loss": 1.2082,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.458441823720932,
      "learning_rate": 0.00075,
      "loss": 1.1711,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 950587686912000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
