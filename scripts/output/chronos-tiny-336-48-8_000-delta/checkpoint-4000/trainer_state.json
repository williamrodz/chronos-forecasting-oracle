{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00625,
      "grad_norm": 0.09138026088476181,
      "learning_rate": 0.00099375,
      "loss": 8.2566,
      "step": 50
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.19953685998916626,
      "learning_rate": 0.0009875,
      "loss": 7.9609,
      "step": 100
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.2895751893520355,
      "learning_rate": 0.00098125,
      "loss": 7.3727,
      "step": 150
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.2968730628490448,
      "learning_rate": 0.000975,
      "loss": 6.6034,
      "step": 200
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.2150256335735321,
      "learning_rate": 0.00096875,
      "loss": 5.9262,
      "step": 250
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.15157243609428406,
      "learning_rate": 0.0009625,
      "loss": 5.5234,
      "step": 300
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.10137688368558884,
      "learning_rate": 0.0009562500000000001,
      "loss": 5.3448,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.08540233224630356,
      "learning_rate": 0.00095,
      "loss": 5.2542,
      "step": 400
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.0947127640247345,
      "learning_rate": 0.00094375,
      "loss": 5.168,
      "step": 450
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.13966746628284454,
      "learning_rate": 0.0009375,
      "loss": 5.0992,
      "step": 500
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.1009388417005539,
      "learning_rate": 0.00093125,
      "loss": 4.9959,
      "step": 550
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.1131671592593193,
      "learning_rate": 0.000925,
      "loss": 4.8754,
      "step": 600
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.19532552361488342,
      "learning_rate": 0.00091875,
      "loss": 4.7507,
      "step": 650
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.1360848993062973,
      "learning_rate": 0.0009125,
      "loss": 4.6097,
      "step": 700
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.20221412181854248,
      "learning_rate": 0.00090625,
      "loss": 4.4826,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19258007407188416,
      "learning_rate": 0.0009000000000000001,
      "loss": 4.3758,
      "step": 800
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.30267953872680664,
      "learning_rate": 0.00089375,
      "loss": 4.2415,
      "step": 850
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.2786795496940613,
      "learning_rate": 0.0008874999999999999,
      "loss": 4.1297,
      "step": 900
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.2837270498275757,
      "learning_rate": 0.00088125,
      "loss": 4.0004,
      "step": 950
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.2847636044025421,
      "learning_rate": 0.000875,
      "loss": 3.8788,
      "step": 1000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.2835167646408081,
      "learning_rate": 0.0008687500000000001,
      "loss": 3.7256,
      "step": 1050
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.4061867892742157,
      "learning_rate": 0.0008625000000000001,
      "loss": 3.6041,
      "step": 1100
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.4506704807281494,
      "learning_rate": 0.00085625,
      "loss": 3.4493,
      "step": 1150
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38295015692710876,
      "learning_rate": 0.00085,
      "loss": 3.3141,
      "step": 1200
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.3366084694862366,
      "learning_rate": 0.00084375,
      "loss": 3.1396,
      "step": 1250
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.37830713391304016,
      "learning_rate": 0.0008375,
      "loss": 3.0184,
      "step": 1300
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.5147254467010498,
      "learning_rate": 0.0008312500000000001,
      "loss": 2.8551,
      "step": 1350
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.5556796789169312,
      "learning_rate": 0.000825,
      "loss": 2.6755,
      "step": 1400
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.5408017039299011,
      "learning_rate": 0.00081875,
      "loss": 2.5423,
      "step": 1450
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.6320555210113525,
      "learning_rate": 0.0008125000000000001,
      "loss": 2.3996,
      "step": 1500
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.5493638515472412,
      "learning_rate": 0.00080625,
      "loss": 2.2484,
      "step": 1550
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5563056468963623,
      "learning_rate": 0.0008,
      "loss": 2.1258,
      "step": 1600
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.492175817489624,
      "learning_rate": 0.00079375,
      "loss": 1.9996,
      "step": 1650
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.6029841899871826,
      "learning_rate": 0.0007875,
      "loss": 1.8931,
      "step": 1700
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5675945281982422,
      "learning_rate": 0.00078125,
      "loss": 1.7697,
      "step": 1750
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.518579363822937,
      "learning_rate": 0.0007750000000000001,
      "loss": 1.7295,
      "step": 1800
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.5345386862754822,
      "learning_rate": 0.00076875,
      "loss": 1.6211,
      "step": 1850
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.5406748056411743,
      "learning_rate": 0.0007624999999999999,
      "loss": 1.5612,
      "step": 1900
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.5253605842590332,
      "learning_rate": 0.00075625,
      "loss": 1.491,
      "step": 1950
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5413185954093933,
      "learning_rate": 0.00075,
      "loss": 1.4281,
      "step": 2000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 0.48558109998703003,
      "learning_rate": 0.00074375,
      "loss": 1.3891,
      "step": 2050
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.5942911505699158,
      "learning_rate": 0.0007375000000000001,
      "loss": 1.3073,
      "step": 2100
    },
    {
      "epoch": 0.26875,
      "grad_norm": 0.44143301248550415,
      "learning_rate": 0.00073125,
      "loss": 1.2738,
      "step": 2150
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.5654096007347107,
      "learning_rate": 0.000725,
      "loss": 1.2397,
      "step": 2200
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.5555434226989746,
      "learning_rate": 0.00071875,
      "loss": 1.1956,
      "step": 2250
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.50776207447052,
      "learning_rate": 0.0007125,
      "loss": 1.1417,
      "step": 2300
    },
    {
      "epoch": 0.29375,
      "grad_norm": 0.4853931665420532,
      "learning_rate": 0.0007062500000000001,
      "loss": 1.1279,
      "step": 2350
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4693106412887573,
      "learning_rate": 0.0007,
      "loss": 1.0991,
      "step": 2400
    },
    {
      "epoch": 0.30625,
      "grad_norm": 0.5733974575996399,
      "learning_rate": 0.00069375,
      "loss": 1.0563,
      "step": 2450
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.5665836334228516,
      "learning_rate": 0.0006875,
      "loss": 1.0504,
      "step": 2500
    },
    {
      "epoch": 0.31875,
      "grad_norm": 0.4826086461544037,
      "learning_rate": 0.00068125,
      "loss": 1.0001,
      "step": 2550
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.5402833819389343,
      "learning_rate": 0.000675,
      "loss": 0.992,
      "step": 2600
    },
    {
      "epoch": 0.33125,
      "grad_norm": 0.5108634233474731,
      "learning_rate": 0.00066875,
      "loss": 0.9549,
      "step": 2650
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.516171932220459,
      "learning_rate": 0.0006625,
      "loss": 0.9347,
      "step": 2700
    },
    {
      "epoch": 0.34375,
      "grad_norm": 0.5127296447753906,
      "learning_rate": 0.00065625,
      "loss": 0.9195,
      "step": 2750
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5323069095611572,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.8932,
      "step": 2800
    },
    {
      "epoch": 0.35625,
      "grad_norm": 0.5344483256340027,
      "learning_rate": 0.00064375,
      "loss": 0.8675,
      "step": 2850
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.5730578899383545,
      "learning_rate": 0.0006374999999999999,
      "loss": 0.8533,
      "step": 2900
    },
    {
      "epoch": 0.36875,
      "grad_norm": 0.5695546269416809,
      "learning_rate": 0.00063125,
      "loss": 0.8593,
      "step": 2950
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.5833132863044739,
      "learning_rate": 0.000625,
      "loss": 0.8586,
      "step": 3000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 0.44841888546943665,
      "learning_rate": 0.00061875,
      "loss": 0.825,
      "step": 3050
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.5473711490631104,
      "learning_rate": 0.0006125000000000001,
      "loss": 0.8022,
      "step": 3100
    },
    {
      "epoch": 0.39375,
      "grad_norm": 0.48151537775993347,
      "learning_rate": 0.00060625,
      "loss": 0.8071,
      "step": 3150
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5261352062225342,
      "learning_rate": 0.0006,
      "loss": 0.7713,
      "step": 3200
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.5495267510414124,
      "learning_rate": 0.00059375,
      "loss": 0.7939,
      "step": 3250
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.5137873888015747,
      "learning_rate": 0.0005875,
      "loss": 0.7878,
      "step": 3300
    },
    {
      "epoch": 0.41875,
      "grad_norm": 0.5995345115661621,
      "learning_rate": 0.0005812500000000001,
      "loss": 0.7643,
      "step": 3350
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.4326428771018982,
      "learning_rate": 0.000575,
      "loss": 0.7428,
      "step": 3400
    },
    {
      "epoch": 0.43125,
      "grad_norm": 0.5645071864128113,
      "learning_rate": 0.00056875,
      "loss": 0.7381,
      "step": 3450
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.5582985281944275,
      "learning_rate": 0.0005625000000000001,
      "loss": 0.7168,
      "step": 3500
    },
    {
      "epoch": 0.44375,
      "grad_norm": 0.571625828742981,
      "learning_rate": 0.00055625,
      "loss": 0.7127,
      "step": 3550
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4788382649421692,
      "learning_rate": 0.00055,
      "loss": 0.7208,
      "step": 3600
    },
    {
      "epoch": 0.45625,
      "grad_norm": 0.47980546951293945,
      "learning_rate": 0.00054375,
      "loss": 0.7161,
      "step": 3650
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.5029617547988892,
      "learning_rate": 0.0005375,
      "loss": 0.7042,
      "step": 3700
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.5133692622184753,
      "learning_rate": 0.00053125,
      "loss": 0.6969,
      "step": 3750
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.4697028398513794,
      "learning_rate": 0.0005250000000000001,
      "loss": 0.678,
      "step": 3800
    },
    {
      "epoch": 0.48125,
      "grad_norm": 0.5060036778450012,
      "learning_rate": 0.00051875,
      "loss": 0.6833,
      "step": 3850
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.5504651665687561,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.6734,
      "step": 3900
    },
    {
      "epoch": 0.49375,
      "grad_norm": 0.5215206742286682,
      "learning_rate": 0.00050625,
      "loss": 0.6485,
      "step": 3950
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4395342767238617,
      "learning_rate": 0.0005,
      "loss": 0.6474,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1901175373824000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
